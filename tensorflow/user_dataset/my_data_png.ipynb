{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import user's own dataset using high level API ---- From TFrecords\n",
    "\n",
    "reference:\n",
    "https://www.tensorflow.org/programmers_guide/datasets\n",
    "\n",
    "Source data: png files under \"my_data\" directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auxiliary function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def _float_feature(value):\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n",
    "\n",
    "def _parse_function(example_proto):\n",
    "    feature = {\n",
    "        'image_raw': tf.FixedLenFeature([180*180*1], tf.float32),\n",
    "        'height': tf.FixedLenFeature([], tf.int64),\n",
    "        'width': tf.FixedLenFeature([], tf.int64)\n",
    "    }\n",
    "    parsed_features = tf.parse_single_example(example_proto, feature)\n",
    "    image = parsed_features['image_raw']\n",
    "    image = tf.reshape(image, [180,180,1])\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save my own images to dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving data ...\n",
      "\n",
      "done\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_name = 'dataset.tfrecords'\n",
    "\n",
    "## save my own images to dataset (100 images of size 180 x 180)\n",
    "print(\"saving data ...\\n\")\n",
    "# build tfrecord file\n",
    "writer = tf.python_io.TFRecordWriter(dataset_name)\n",
    "# reader for original data\n",
    "files = glob.glob( os.path.join('my_data', '*.png') )\n",
    "files.sort()\n",
    "# save my images to dataset\n",
    "for i in range(len(files)):\n",
    "    img = cv2.imread(files[i], cv2.IMREAD_GRAYSCALE)\n",
    "    img = np.expand_dims(img, 2)\n",
    "    # pixels are stored by 1 byte, range [0, 255]\n",
    "    # now should convert it to float32 and normalize\n",
    "    img = np.float32(img) / 255.\n",
    "    height = img.shape[0]\n",
    "    width = img.shape[1]\n",
    "    feature = {\n",
    "        'image_raw': _float_feature(img.reshape( (height*width) )),\n",
    "         'height': _int64_feature(height),\n",
    "        'width':  _int64_feature(width)\n",
    "    }\n",
    "    example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    writer.write(example.SerializeToString())\n",
    "writer.close()\n",
    "print(\"done\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the dataset and display them with tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data ...\n",
      "\n",
      "\n",
      "End of dataset\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## load the dataset and display them with tensorboard\n",
    "print(\"loading data ...\\n\")\n",
    "# 1. build Dataset object\n",
    "dataset = tf.data.TFRecordDataset(dataset_name)\n",
    "# 2. parsing TFrecords (the _parse_function only output the raw image, not height and width)\n",
    "dataset = dataset.map(_parse_function)\n",
    "# 3. shuffle the dataset\n",
    "dataset = dataset.shuffle(buffer_size=10000)\n",
    "# 4. multiple epochs & batching\n",
    "dataset = dataset.batch(64) # batch size: 64\n",
    "dataset = dataset.repeat(10) # 10 epoches\n",
    "# construct iterator\n",
    "# iterator.get_next() returns a batch, not a single image\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "next_element = iterator.get_next()\n",
    "# read data\n",
    "img_batch = tf.placeholder(tf.float32, [None, 180, 180, 1])\n",
    "tf.summary.image(name='display', tensor=img_batch, max_outputs=6)\n",
    "step = 0\n",
    "with tf.Session() as sess:\n",
    "    summary = tf.summary.merge_all()\n",
    "    summ_writer = tf.summary.FileWriter('logs', sess.graph)\n",
    "    while True:\n",
    "        try:\n",
    "            batch_img = sess.run(next_element)\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print('\\nEnd of dataset\\n')\n",
    "            break\n",
    "        summ = sess.run(summary, {img_batch: batch_img})\n",
    "        summ_writer.add_summary(summ, step)\n",
    "        summ_writer.flush()\n",
    "        step += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
